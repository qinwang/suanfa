1
00:00:02,025 --> 00:00:07,024
Next we're going to look at the use of the
binary heap data structure to implement a

2
00:00:07,024 --> 00:00:12,629
clever sorting algorithm known as
Heapsort. So here's the basic plan. What

3
00:00:12,629 --> 00:00:19,588
we're going to do is we have our end keys
and we'll have them in an array. We'll

4
00:00:19,588 --> 00:00:26,037
view that array as eventually being a max
heap. So what we have to do first is to

5
00:00:26,060 --> 00:00:33,014
rearrange the keys in the array to heap
order it. So just make it so that every

6
00:00:33,014 --> 00:00:39,014
key is larger than it's two children. And
for example, the largest of all the keys

7
00:00:39,014 --> 00:00:45,080
is at the root. And then, the next phase
would be to take that heap ordered array

8
00:00:46,183 --> 00:00:51,096
and get, get it to be a sorted result in,
in place. And again, the, heap is stored

9
00:00:51,096 --> 00:00:57,083
in the array, with the first key position
one, next to position two and three and

10
00:00:57,083 --> 00:01:03,092
like that. So the end result would be like
that, with, no keys in the heap, but all

11
00:01:03,092 --> 00:01:08,089
the keys in the array in sorted order. So
it's a little exercise in abstraction.

12
00:01:08,089 --> 00:01:13,030
Part of the array is the heap. Part of the
array is the sorted sub array. And

13
00:01:13,030 --> 00:01:18,004
eventually we bring it down to the whole
thing being sorted. It's very little code

14
00:01:18,004 --> 00:01:22,067
beyond the basic heap code that we've
looked at can get this implemented. And

15
00:01:22,067 --> 00:01:30,029
that's called Heapsort. Let's take a demo
of how Heapsort works in our example. So

16
00:01:30,051 --> 00:01:36,068
the idea is we're going to use a bottom up
method. So all that means is we start with

17
00:01:36,068 --> 00:01:42,056
an array in arbitrary order and then we're
going to work from the bottom up to make

18
00:01:42,056 --> 00:01:48,017
sure that it's heap order. Well all the
nodes with no children are heap order,

19
00:01:48,017 --> 00:01:54,041
they are only a size one, the first one we
have to worry about is this one here the

20
00:01:54,041 --> 00:01:59,079
root, the root. We haven't examined yet,
it's children are heap ordered so it's a

21
00:01:59,079 --> 00:02:04,089
small heap of size three that may not be
heap ordered. In this case it's not

22
00:02:04,089 --> 00:02:10,006
because one of the children is larger, so
that's where things are going to start. We

23
00:02:10,006 --> 00:02:15,016
have a lot of one node heaps and then
we're going to have to perform the sync

24
00:02:15,016 --> 00:02:20,001
operation on this one, that node five,
that's, in this case just to change it

25
00:02:20,001 --> 00:02:25,090
with it's parent. And then proceeding in
that way, moving bottom up or moving from

26
00:02:25,090 --> 00:02:30,708
right to left, the next thing we do is but
then worry about a three node heap that's

27
00:02:30,708 --> 00:02:35,753
heap ordered and we're fine. Now we'll
move over to the T and again, that's the

28
00:02:35,753 --> 00:02:40,623
root of a three node heap that's heap
ordered except at the root. We may need to

29
00:02:40,623 --> 00:02:45,642
fix it with the sync operation. In this
case nothing is required because it's

30
00:02:45,642 --> 00:02:50,606
larger than its children, so we have a
three node heap. And then we move one more

31
00:02:50,606 --> 00:02:55,614
to the left, now we're looking at the R.
Again root of a three node heap may or may

32
00:02:55,614 --> 00:03:00,679
not be heap ordered, we do have to do the
sync operation. In this case that brings

33
00:03:00,679 --> 00:03:06,633
the X up. A three node heap. Now we go to
two. Now that's the root of a seven node

34
00:03:06,633 --> 00:03:11,663
heap. We know the two three node heaps
that are the children are heap ordered but

35
00:03:11,663 --> 00:03:17,555
we may have to correct the heap ordering
at the root so we do a sync on two. And

36
00:03:17,555 --> 00:03:22,373
that's going to involve, exchanging with
the T, because T is larger than O. And

37
00:03:22,373 --> 00:03:28,209
exchanging with the P because P is larger
than O. Now that heap is a seven node heap

38
00:03:28,209 --> 00:03:32,870
that's all heap ordered, and then the last
thing is to do the root of the whole thing

39
00:03:32,870 --> 00:03:38,015
and again, now the two sub trees are heap
ordered, that's what we mean by bottom up,

40
00:03:38,015 --> 00:03:43,548
we took care of the heep ordering from the
bottom up. And so we'll do a sync on the S

41
00:03:43,548 --> 00:03:50,037
and bring it into a heap ordering, so
that's with just a few exchanges we got

42
00:03:50,037 --> 00:03:56,082
that whole array heap order, and now what
we want to do is take advantage of the

43
00:03:56,082 --> 00:04:02,063
heap ordering in the array to do a sort.
And the concept is very simple. Right away

44
00:04:02,063 --> 00:04:07,035
we have the maximum element in the array
right at the root, we want that to be at

45
00:04:07,035 --> 00:04:11,090
the end so that's what we're going to do
and that's what we're going to do is just

46
00:04:11,090 --> 00:04:16,097
put it at the end. We exchange the element
at the root with the last element. Pull it

47
00:04:16,097 --> 00:04:22,026
off the heap and then that's our example.
We might have violated the heap order

48
00:04:22,026 --> 00:04:27,025
condtion at the heap right now. So now we
have to do a sync operation on, on the E.

49
00:04:27,256 --> 00:04:32,085
And so, it's larger than, it's both
children, and the larger of the two

50
00:04:32,085 --> 00:04:38,074
children is T, so we promote the T. And
the P is larger, the two children promote

51
00:04:38,074 --> 00:04:44,291
that and then finally, the E comes down to
the bottom. So now that's one step in the

52
00:04:44,291 --> 00:04:49,281
sort, we got the largest element off. Now
the next largest element in the array is

53
00:04:49,281 --> 00:04:54,722
now at the root of the heap. We're going
to do the same thing, exchange it with the

54
00:04:54,722 --> 00:05:00,555
last element in the heap. Then now that T
is in its final position in the sorted

55
00:05:00,555 --> 00:05:06,319
array, we take it off the heap. So now,
we've got a heap with nine elements and

56
00:05:06,319 --> 00:05:12,003
two of the elements in the array are
already in their final position. And now

57
00:05:12,003 --> 00:05:17,068
this one's not heap ordered, so we have to
exchange over the largest of its two

58
00:05:17,068 --> 00:05:22,489
children. In this case that involves
regarding the S and the R. Now it's heap

59
00:05:22,489 --> 00:05:27,205
ordered. So that's the end of the two
steps in Heapsort. And then we just keep

60
00:05:27,205 --> 00:05:32,038
going. Pulling off the largest element
from the heap. Exchanging it with the.

61
00:05:32,038 --> 00:05:36,688
Element in the heap in the largest
position in the array which brings that

62
00:05:36,688 --> 00:05:42,335
element into its final position in the
sorted array. And then adjusting the heap

63
00:05:42,335 --> 00:05:48,563
ordering with the sync operation. So that
E again is going to come down and now it

64
00:05:48,563 --> 00:05:54,208
only goes down one step in this case. So
now R exchanges with M. It's in it's final

65
00:05:54,208 --> 00:05:59,607
position and you can see down at the
bottom, the large elements in the array

66
00:05:59,607 --> 00:06:04,928
filling in, in their final position, in
the, the left part of the array is

67
00:06:04,928 --> 00:06:10,365
representing the heap. The R goes off the
heap, do the sync operation on the M, and

68
00:06:10,365 --> 00:06:17,722
now we have a heap ordered array. So now
do the P, exchange that with the A. Take

69
00:06:17,722 --> 00:06:24,758
it off the heap. Do the sync operation on
the A. Now we're going to do the O.

70
00:06:24,758 --> 00:06:31,518
Exchange that with the E. Take it off the
heap. Do the sync operation on E which

71
00:06:31,518 --> 00:06:36,903
involves promoting the larger of its two
children, until it gets to the bottom, or

72
00:06:36,903 --> 00:06:42,935
a place where it's larger than both its
children. So now we have, just five

73
00:06:42,935 --> 00:06:49,002
elements left. We'll, get the M. Do heap
ordering on the, heap of four and that

74
00:06:49,002 --> 00:06:55,241
only involves one exchange. Now we get the
L. A exchange for the larger of its two

75
00:06:55,241 --> 00:07:01,179
children. While, they're both the same, so
i t goes with the left one. That's the

76
00:07:01,179 --> 00:07:07,649
heap of size three. Pull off the first E,
it's already heap ordered. Pull off that

77
00:07:07,649 --> 00:07:14,322
E. And, now we are left with only one
element in the heap in this in the first

78
00:07:14,322 --> 00:07:22,216
position, so there is nothing to do. So
with a series of in exchange and then sync

79
00:07:22,216 --> 00:07:30,939
operations, we pull the sorted array out
of the heap. Okay. This, slide summarizes

80
00:07:30,939 --> 00:07:36,622
the code for, heap construction. And as
you can see, it's a one liner. We go

81
00:07:36,622 --> 00:07:42,518
backwards through the heap. Starting at N
over two because the, N over, half of the,

82
00:07:42,518 --> 00:07:48,241
right most half of the array is just
little heaps of size one. We just go

83
00:07:48,241 --> 00:07:55,749
backwards doing a sync starting at K. So
that's the first piece of code for heap

84
00:07:55,749 --> 00:08:05,907
ordering an array with arbitrary values
and then these diagrams summarize the sync

85
00:08:05,907 --> 00:08:12,567
calls that, that we just went through in
the demo starting at five, four, three,

86
00:08:12,567 --> 00:08:17,882
two, one. As you can see, only one, two,
three, four, five exchanges are needed to

87
00:08:17,882 --> 00:08:24,541
bring this into heap order. Then the
second pass again that's only a two liner,

88
00:08:24,541 --> 00:08:31,700
we exchange the first element with the one
at the end and then decrement the size of

89
00:08:31,700 --> 00:08:38,450
the heap and then do a sync operations.
And these diagrams summarize the sync

90
00:08:38,450 --> 00:08:45,306
operations that we showed in the demo. On
every smaller heap, now we continue just

91
00:08:45,306 --> 00:08:51,662
performing sync operations at the root
until we get a completely sorted array. So

92
00:08:51,879 --> 00:08:58,279
given the sink implementation, we had done
a one liner for the first pass and a three

93
00:08:58,283 --> 00:09:05,392
liner for the second pass so that gives a
complete implementation of heap sort with

94
00:09:05,392 --> 00:09:11,856
the code that we have given so for, so
far. There's is one little detail when you

95
00:09:11,856 --> 00:09:18,079
are sorting an array of course position
zero comes into account and we've been

96
00:09:18,079 --> 00:09:24,095
building our heaps from position one. So,
but we can take care of that in the less

97
00:09:24,095 --> 00:09:30,769
and exchange methods by just decrementing
the indices in those methods to have it

98
00:09:30,769 --> 00:09:36,778
work as if the array were zero through n.
That's a little implementation detail, but

99
00:09:36,778 --> 00:09:42,171
otherwise this is a fine sword
implementation, that actually is very

100
00:09:42,171 --> 00:09:48,953
little code, and its got a place in, in
the theory of algorithm, that I will talk

101
00:09:48,953 --> 00:09:54,935
about in a second. This is just another
trace without the data-structure shown, to

102
00:09:54,935 --> 00:10:00,875
just show in our standard way, the
elements in black and red are the ones

103
00:10:00,875 --> 00:10:07,357
that are touched and the elements in grey
are the ones that are not touched at all.

104
00:10:07,357 --> 00:10:12,853
And to just show that this thing gets the
sort done with touching relatively few

105
00:10:12,853 --> 00:10:18,109
elements. That's a trace. Let's look at an
animation, an animation with Heapsort is

106
00:10:18,109 --> 00:10:24,057
interesting to watch so the construction
of the heap happens in a blink and now

107
00:10:24,057 --> 00:10:30,650
it's pulling off the largest elements,
moving from right to left. So again, a

108
00:10:30,650 --> 00:10:37,218
very efficient way to get a sorting job
done. So what about the mathematical

109
00:10:37,218 --> 00:10:42,937
analysis? Well the mathematical analysis,
for the Heapsort part is pretty easy. N

110
00:10:42,937 --> 00:10:48,827
times, we're doing a sink operation, and
the size of the heap is at most lg N so

111
00:10:48,827 --> 00:10:54,914
it's N lg N. The construction, actually,
it turns out although it's a little more

112
00:10:54,914 --> 00:11:00,475
complicated to prove, that it always uses
just a linear number of comparison

113
00:11:00,475 --> 00:11:05,277
exchanges. And that's an interesting
result in itself. You can build a heap

114
00:11:05,277 --> 00:11:10,614
from N values in linear time. And then,
and then lg N more time. You can sort from

115
00:11:10,614 --> 00:11:16,475
that heap and that's significance be,
significant because it's the first sorting

116
00:11:16,475 --> 00:11:22,530
algorithm that we've seen that is both in
place. And manages to get the sorting job

117
00:11:22,530 --> 00:11:28,283
done with guaranteed analogs and compares.
Mergesort doesn't do that. It takes linear

118
00:11:28,283 --> 00:11:35,028
extra space. Quicksort doesn't do that. It
takes quadratic time in a worse case even

119
00:11:35,028 --> 00:11:41,073
though we make that unlikely by random
shuffling. It still takes quadratic time

120
00:11:41,073 --> 00:11:47,184
in the worse case but Heapsort does both.
Now there is more complicated versions of

121
00:11:47,184 --> 00:11:51,535
Mergesort and Quicksort that can do this
in theory but Heapsort is pretty simple

122
00:11:51,535 --> 00:11:56,623
algorithm that gets both done, so in a job
interview somebody asks you what's an

123
00:11:56,623 --> 00:12:01,142
in-place sorting algorithm that's
guaranteed N lg n? Your answer's going to

124
00:12:01,142 --> 00:12:06,183
be Heapsort. Now in practice Heapsort is
actually not used that much for a couple

125
00:12:06,183 --> 00:12:11,598
of reasons. And they might ask you these
on your job interview too. First thing is

126
00:12:11,598 --> 00:12:17,761
the inner loop is longer than Quicksorts.
Like Mergesort there is more things to do

127
00:12:17,761 --> 00:12:23,016
in the inner loop. There is that compare
are the two children bigger, then compare.

128
00:12:23,016 --> 00:12:28,915
So there are two compares that get done at
N lg N times. And then there is some that

129
00:12:28,915 --> 00:12:34,269
array index arithmetic. The other thing
that is probably more significant on

130
00:12:34,269 --> 00:12:39,675
modern machines is. That the references to
memory are all over the place when it's a

131
00:12:39,675 --> 00:12:44,487
huge array, so it's not a good algorithm
for a situation where there's caching

132
00:12:44,487 --> 00:12:49,005
which is almost everywhere nowadays. It
doesn't have a local reference, like

133
00:12:49,005 --> 00:12:53,462
Quicksort does. It's always refers to
something that's nearby something else

134
00:12:53,462 --> 00:12:58,602
that I just referred to. So if a big block
of things comes into memory, there's no

135
00:12:58,602 --> 00:13:03,515
more extra costs, whereas Heapsort is
going to look far away from the current

136
00:13:03,515 --> 00:13:08,643
place as it goes down the tree and that
makes it slower in a lot of situations.

137
00:13:08,643 --> 00:13:13,770
And on the other thing is it's not stable,
sometimes people choose to use Mergesort

138
00:13:13,770 --> 00:13:19,781
in practice because of the stability but
Heapsort isnot stable for the usual reason

139
00:13:20,015 --> 00:13:26,139
that it does long distance exchanges that
might bring items that have equal keys

140
00:13:26,139 --> 00:13:32,734
back out of order. So that, that, that's
our full summary of sorting algorithms to

141
00:13:32,734 --> 00:13:39,075
and completes our treatment of sorting
algorithms with Heapsort. And this is just

142
00:13:39,075 --> 00:13:46,082
adding the Heapsort line to the table.
It's in place we don't use any auxiliary

143
00:13:46,082 --> 00:13:53,057
array it's not stable, but its worst-case
guaranteed time is proportional to N lg N

144
00:13:53,057 --> 00:14:00,045
as well as the average and, and the best
this is not a result but that's also the

145
00:14:00,045 --> 00:14:07,061
case so it's N lg N guarantee N place, but
it's not stable, and we still have the

146
00:14:07,061 --> 00:14:14,370
hope that someday somebody will develop a
simple in-place stable worst case N lg N

147
00:14:14,370 --> 00:14:20,036
algorithm but we're not quite there yet.
And that completes our treatment of

148
00:14:20,036 --> 00:14:23,074
sorting algorithms with the Heapsort
algorithm.
